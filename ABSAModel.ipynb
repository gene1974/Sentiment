{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from transformers import BertModel, AutoTokenizer\n",
    "\n",
    "from crf import CRF\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import logging\n",
    "def logger(content):\n",
    "    logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "    log_format = '[%(asctime)s] %(message)s'\n",
    "    date_format = '%Y%m%d %H:%M:%S'\n",
    "    logging.basicConfig(level = logging.DEBUG, format = log_format, datefmt = date_format)\n",
    "    logging.info(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'path': '/data/pretrained/bert-base-chinese/',\n",
    "    'bert_out_dim': 768,\n",
    "    'n_class': 9, \n",
    "    'dropout': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20240406 22:21:03] Load dataset: 8670\n",
      "[20240406 22:21:03] words: 2250, variety: 26, category: 9\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "words = set()\n",
    "varietys = set()\n",
    "categorys = set()\n",
    "with open('./Dataset/comment_labeled.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        comment_id = data['comment_id']\n",
    "        comment_variety = data['comment_variety'] # 花生\n",
    "        user_star = data['user_star'] # 2\n",
    "        comment_text = data['comment_text']\n",
    "        comment_units = data['comment_units'] # 多个四元组\n",
    "        dataset.append({\n",
    "            'id': comment_id, \n",
    "            'variety': comment_variety, \n",
    "            'user_star': user_star, \n",
    "            'text': comment_text, \n",
    "            'comment': comment_units, \n",
    "        })\n",
    "        words |= set(comment_text)\n",
    "        varietys.add(comment_variety)\n",
    "        categorys |= {i['aspect'] for i in comment_units}\n",
    "\n",
    "logger('Load dataset: {}'.format(len(dataset)))\n",
    "logger('words: {}, variety: {}, category: {}'.format(len(words), len(varietys), len(categorys)))\n",
    "\n",
    "word_list = list(words)\n",
    "word_list.insert(0, '[PAD]')\n",
    "word_list.insert(1, '[UNK]')\n",
    "word_dict = {word_list[i]: i for i in range(len(word_list))}\n",
    "\n",
    "\n",
    "variety_list = list(varietys)\n",
    "variety_list.insert(0, '<PAD>')\n",
    "variety_list.insert(1, '<OOV>')\n",
    "variety_dict = {variety_list[i]: i for i in range(len(variety_list))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20240406 22:21:40] Load Glove Word embedding: torch.Size([2252, 300])\n"
     ]
    }
   ],
   "source": [
    "def load_glove(word_to_ix, dim = 100):\n",
    "    if dim == 100:\n",
    "        path = '/data/pretrained/Glove/glove.6B.100d.txt'\n",
    "    elif dim == 300:\n",
    "        path = '/data/pretrained/Glove/glove.840B.300d.txt'\n",
    "    word_emb = []\n",
    "    word_emb = torch.zeros((len(word_to_ix), dim), dtype = torch.float)\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = line.strip().split(' ') # [word emb1 emb2 ... emb n]\n",
    "            word = data[0]\n",
    "            if word in word_to_ix:\n",
    "                word_emb[word_to_ix[word]] = torch.tensor([float(i) for i in data[1:]])\n",
    "    return word_emb\n",
    "word_emb = load_glove(word_dict, 300)\n",
    "\n",
    "logger('Load Glove Word embedding: {}'.format(word_emb.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-A': 1, 'I-A': 2, 'E-A': 3, 'S-A': 4, 'B-O': 5, 'I-O': 6, 'E-O': 7, 'S-O': 8}\n",
      "{'text': '这次买的没有之前买的品质好，以前每一个颗粒饱满，这次的质量参差不齐。', 'word_ids': [1482, 473, 2186, 562, 1207, 1686, 979, 752, 2186, 562, 2091, 57, 2074, 468, 316, 752, 543, 18, 1453, 2124, 2104, 597, 516, 468, 1482, 473, 562, 57, 2187, 1145, 493, 1509, 1141, 1066, 0, 0, 0, 0, 0, 0], 'word_masks': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0], 'labels': [5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 7, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# tag BIO label\n",
    "tag_list = ['O'] + [i + '-A' for i in ['B', 'I', 'E', 'S']] + [i + '-O' for i in ['B', 'I', 'E', 'S']]\n",
    "tag_dict = {tag_list[i]: i for i in range(len(tag_list))}\n",
    "print(tag_dict)\n",
    "\n",
    "def tagging(text, aspects, opinions):\n",
    "    tags = ['O'] * len(text)\n",
    "    for t in sorted(aspects, key = lambda x: x['tail'] - x['head']):\n",
    "        if t['tail'] - t['head'] == 1:\n",
    "            tags[t['head']] = 'S-A'\n",
    "        else:\n",
    "            tags[t['head']] = 'B-A'\n",
    "            for i in range(t['head'] + 1, t['tail'] - 1):\n",
    "                tags[i] = 'I-A'\n",
    "            tags[t['tail'] - 1] = 'E-A'\n",
    "    for o in sorted(opinions, key = lambda x: x['tail'] - x['head']):\n",
    "        if o['tail'] - o['head'] == 1:\n",
    "            tags[o['head']] = 'S-O'\n",
    "        else:\n",
    "            tags[o['head']] = 'B-O'\n",
    "            for i in range(o['head'] + 1, o['tail'] - 1):\n",
    "                tags[i] = 'I-O'\n",
    "            tags[o['tail'] - 1] = 'E-O'\n",
    "    return tags\n",
    "\n",
    "sen_len = 40\n",
    "tokenizer = AutoTokenizer.from_pretrained('/data/pretrained/bert-base-chinese/')\n",
    "tagged_dataset = []\n",
    "for item in dataset:\n",
    "    aspects = []\n",
    "    opinions = []\n",
    "    for comment in item['comment']: # 每个 comment 是一个四元组，描述一个方面\n",
    "        aspects += comment['target']\n",
    "        opinions += comment['opinion']\n",
    "    text = item['text']\n",
    "    tags = tagging(text, aspects, opinions) + ['O'] * (sen_len - len(text))\n",
    "    word_ids = [word_dict[word] if word in word_dict else word_dict['[UNK]'] for word in item['text']] + \\\n",
    "               [word_dict['[PAD]']] * (sen_len - len(text))\n",
    "    word_masks = [1] * len(text) + [0] * (sen_len - len(text))\n",
    "    tag_ids = [tag_dict[i] for i in tags]\n",
    "    tagged_dataset.append({\n",
    "        'text': item['text'],\n",
    "        'word_ids': word_ids, \n",
    "        'word_masks': word_masks,\n",
    "        'labels': tag_ids\n",
    "    })\n",
    "print(tagged_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentence_entity(text, tags, tag_list):\n",
    "    tags = [tag_list[i] for i in tags]\n",
    "    entity = []\n",
    "    count = len(text)\n",
    "    i = 0\n",
    "    while i < count:\n",
    "        if tags[i][0] == 'B':\n",
    "            j = i + 1\n",
    "            while j < count:\n",
    "                if tags[j][0] == 'E':\n",
    "                    break\n",
    "                else:\n",
    "                    j += 1\n",
    "            entity.append({\n",
    "                \"text\": ''.join(text[i: j]),\n",
    "                \"start_index\": i,\n",
    "                \"end_index\": j,\n",
    "                \"label\": tags[i][2:]\n",
    "            })\n",
    "            i = j + 1\n",
    "        elif tags[i][0] == 'S':\n",
    "            entity.append({\n",
    "                \"text\": text[i],\n",
    "                \"start_index\": i,\n",
    "                \"end_index\": i,\n",
    "                \"label\": tags[i][2:]\n",
    "            })\n",
    "            i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "    return entity\n",
    "\n",
    "# print(tokens[0], labels[0])\n",
    "# label_sentence_entity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_metrics(pred_entities, gold_entities):\n",
    "    correct_num = 0\n",
    "    predict_num = 0\n",
    "    gold_num = 0\n",
    "    for i in range(len(pred_entities)):\n",
    "        gold_entity = gold_entities[i]\n",
    "        pred_entity = pred_entities[i]\n",
    "        gold_num += len(gold_entity)\n",
    "        predict_num += len(pred_entity)\n",
    "        for entity in gold_entity:\n",
    "            if entity in pred_entity:\n",
    "                correct_num += 1\n",
    "    precision = correct_num / (predict_num + 0.000000001)\n",
    "    recall = correct_num / (gold_num + 0.000000001)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 0.000000001)\n",
    "    return precision, recall, f1\n",
    "\n",
    "# decode from BIOES\n",
    "def decode_ner(pred, labels, texts):\n",
    "    pred_entities = []\n",
    "    gold_entities = []\n",
    "    for j in range(pred.shape[0]):\n",
    "        gold_entity = label_sentence_entity(texts[j], labels[j].tolist(), tag_list)\n",
    "        pred_entity = label_sentence_entity(texts[j], pred[j], tag_list) # text, start_index, end_index, label\n",
    "        pred_entities.append(pred_entity)\n",
    "        gold_entities.append(gold_entity)\n",
    "        # precision, recall, f1 = ner_metrics(pred_entities, gold_entities)\n",
    "    return pred_entities, gold_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def save_model(model, path):\n",
    "    ts = time.strftime('%m%d%H%M', time.localtime())\n",
    "    torch.save(model.state_dict(), '{}.{}'.format(path, ts))\n",
    "    print('Save model to', '{}.{}'.format(path, ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, tag_list):\n",
    "    model.eval()\n",
    "    correct_num, predict_num, gold_num = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            tokens, masks, labels, texts = batch['tokens'], batch['masks'], batch['labels'], batch['texts']\n",
    "            sen_len = max(len(text) for text in texts)\n",
    "            labels = labels[:, :sen_len]\n",
    "            pred = model.predict(**batch)[:, :sen_len]\n",
    "            # print(pred)\n",
    "            for j in range(labels.shape[0]):\n",
    "                gold_entity = label_sentence_entity(texts[j], labels[j].tolist(), tag_list)\n",
    "                pred_entity = label_sentence_entity(texts[j], pred[j], tag_list)\n",
    "                gold_num += len(gold_entity)\n",
    "                predict_num += len(pred_entity)\n",
    "                for entity in gold_entity:\n",
    "                    if entity in pred_entity:\n",
    "                        correct_num += 1\n",
    "                # print(gold_entity)\n",
    "                # print(pred_entity)\n",
    "                # return\n",
    "    precision = correct_num / (predict_num + 0.000000001)\n",
    "    recall = correct_num / (gold_num + 0.000000001)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 0.000000001)\n",
    "    logger('[Test] Precision: {:.6f} Recall: {:.6f} F1: {:.6f}'.format(precision, recall, f1))\n",
    "    return precision, recall, f1\n",
    "\n",
    "# evaluate(model, test_loader, tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(model, train_loader, valid_loader, epochs = 100, lr = 1e-4, patience = 5):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 3e-4)\n",
    "    early_stopping = EarlyStopping(patience = patience, verbose = False)\n",
    "    entrophy = nn.CrossEntropyLoss()\n",
    "    avg_train_losses = []\n",
    "    avg_valid_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        train_correct, train_total, valid_correct, valid_total = 0, 0, 0, 0\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        model.train()\n",
    "        for _, batch in enumerate(train_loader):\n",
    "            tokens, masks, labels = batch\n",
    "            sen_len = torch.max(torch.sum(masks, dim = 1, dtype = torch.int64)).item()\n",
    "            tokens = tokens[:, :sen_len]\n",
    "            masks = masks[:, :sen_len]\n",
    "            labels = labels[:, :sen_len]\n",
    "            optimizer.zero_grad()\n",
    "            output = model(tokens, masks) # (n_batch, n_token, n_class)\n",
    "            loss = entrophy(output.permute(0, 2, 1), labels)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            predict = model.predict(tokens, masks, labels) # (n_batch, n_tokens)\n",
    "            train_correct += torch.sum(predict[masks == 1] == labels[masks == 1]).item()\n",
    "            train_total += torch.sum(masks == 1).item()\n",
    "        avg_train_loss = np.average(train_losses)\n",
    "        avg_train_losses.append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            gold_num = 0\n",
    "            predict_num = 0\n",
    "            correct_num = 0\n",
    "            for i, batch in enumerate(valid_loader):\n",
    "                tokens, masks, labels = batch\n",
    "                sen_len = torch.max(torch.sum(masks, dim = 1, dtype = torch.int64)).item()\n",
    "                tokens = tokens[:, :sen_len]\n",
    "                masks = masks[:, :sen_len]\n",
    "                labels = labels[:, :sen_len]\n",
    "                output = model(tokens, masks)\n",
    "                loss = entrophy(output.permute(0, 2, 1), labels)\n",
    "                valid_losses.append(loss.item())\n",
    "                predict = torch.max(output, dim = 2).indices # (n_batch, n_tokens)\n",
    "                valid_correct += torch.sum(predict[masks == 1] == labels[masks == 1]).item()\n",
    "                valid_total += torch.sum(masks == 1).item()\n",
    "                for j in range(labels.shape[0]):\n",
    "                    gold_entity = label_sentence_entity(text[j], labels[j].tolist(), tag_list)\n",
    "                    pred_entity = label_sentence_entity(text[j], predict[j], tag_list)\n",
    "                    gold_num += len(gold_entity)\n",
    "                    predict_num += len(pred_entity)\n",
    "                    for entity in gold_entity:\n",
    "                        if entity in pred_entity:\n",
    "                            correct_num += 1\n",
    "            avg_valid_loss = np.average(valid_losses)\n",
    "            avg_valid_losses.append(avg_valid_loss)\n",
    "        precision = correct_num / (predict_num + 0.000000001)\n",
    "        recall = correct_num / (gold_num + 0.000000001)\n",
    "        f1 = 2 * precision * recall / (precision + recall + 0.000000001)\n",
    "        logger('[Test] Precision: {:.8f} Recall: {:.8f} F1: {:.8f}'.format(precision, recall, f1))\n",
    "        \n",
    "        logger('[epoch {:d}] TLoss: {:.3f} VLoss: {:.3f} TAcc: {:.3f} VAcc: {:.3f}'.format(\n",
    "                epoch + 1, avg_train_loss, avg_valid_loss, train_correct / train_total, valid_correct / valid_total))\n",
    "        early_stopping(avg_valid_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            logger(\"Early stopping\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, loss_mode = 'linear', epochs = 100, lr = 1e-5):\n",
    "    print('Train {} model with lr = {}'.format(model.__class__.__name__, lr))\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    early_stopping = EarlyStopping(patience = 5, verbose = False)\n",
    "    entrophy = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        model.train()\n",
    "        for _, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            if loss_mode == 'linear':\n",
    "                output = model(**batch) # (n_batch, n_token, n_class)\n",
    "                loss = entrophy(output.permute(0, 2, 1), batch['labels'])\n",
    "            elif loss_mode == 'crf':\n",
    "                loss = model(**batch) # (n_batch, n_token, n_class)\n",
    "            else:\n",
    "                raise ValueError('Invalid loss mode %s', loss_mode)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            predict = model.predict(**batch) # (n_batch, n_tokens)\n",
    "            train_correct += torch.sum(torch.logical_and(predict == batch['labels'][:, :predict.shape[1]], batch['masks'] == 1)).item()\n",
    "            train_total += torch.sum(batch['masks'] == 1).item()\n",
    "        avg_train_loss = np.average(train_losses)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(valid_loader):\n",
    "                if loss_mode == 'linear':\n",
    "                    output = model(**batch) # (n_batch, n_token, n_class)\n",
    "                    loss = entrophy(output.permute(0, 2, 1), batch['labels'])\n",
    "                elif loss_mode == 'crf':\n",
    "                    loss = model(**batch) # (n_batch, n_token, n_class)\n",
    "                else:\n",
    "                    raise ValueError('Invalid loss mode %s', loss_mode)\n",
    "                valid_losses.append(loss.item())\n",
    "                predict = model.predict(**batch)\n",
    "                valid_correct += torch.sum(torch.logical_and(predict == batch['labels'][:, :predict.shape[1]], batch['masks'] == 1)).item()\n",
    "                valid_total += torch.sum(batch['masks'] == 1).item()\n",
    "            avg_valid_loss = np.average(valid_losses)\n",
    "        precision, recall, f1 = evaluate(model, valid_loader, tag_list)\n",
    "        \n",
    "        # logger('[epoch {:d}] TLoss: {:.3f} VLoss: {:.3f} TAcc: {:.3f} VAcc: {:.3f}'.format(\n",
    "        #     epoch + 1, avg_train_loss, avg_valid_loss, train_correct / train_total, valid_correct / valid_total))\n",
    "        logger('[epoch {:d}] TLoss: {:.3f} VLoss: {:.3f} TAcc: {:.3f} VAcc: {:.3f}'.format(\n",
    "            epoch + 1, avg_train_loss, avg_valid_loss, train_correct / train_total, valid_correct / valid_total))\n",
    "        logger('Precision: {:.3f} Recall: {:.3f} F1: {:.3f}'.format(precision, recall, f1))\n",
    "        early_stopping(-valid_correct / valid_total, model)\n",
    "        if early_stopping.early_stop:\n",
    "            logger(\"Early stopping\")\n",
    "            break\n",
    "    save_model(model, './results/{}.{}'.format(model.__class__.__name__, lr))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM + Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_lstm(batch):\n",
    "    tokens = torch.tensor([item['word_ids'] for item in batch], dtype = torch.long, device = device)\n",
    "    masks = torch.tensor([item['word_masks'] for item in batch], dtype = torch.bool, device = device)\n",
    "    labels = torch.tensor([item['labels'] for item in batch], dtype = torch.long, device = device)\n",
    "    sen_len = torch.max(torch.sum(masks, dim = 1, dtype = torch.int64)).item()\n",
    "    tokens = tokens[:, :sen_len]\n",
    "    masks = masks[:, :sen_len]\n",
    "    labels = labels[:, :sen_len]\n",
    "    return {\n",
    "        'tokens': tokens, \n",
    "        'masks': masks, \n",
    "        'labels': labels,\n",
    "        'texts': [item['text'] for item in batch],\n",
    "    }\n",
    "\n",
    "n_train, n_dev = int(0.6 * len(tagged_dataset)), int(0.2 * len(tagged_dataset))\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(tagged_dataset[:n_train], batch_size = batch_size, collate_fn = collate_lstm)\n",
    "valid_loader = DataLoader(tagged_dataset[n_train: n_train + n_dev], batch_size = batch_size, collate_fn = collate_lstm)\n",
    "test_loader = DataLoader(tagged_dataset[n_train + n_dev:], batch_size = batch_size, collate_fn = collate_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLinear(nn.Module):\n",
    "    def __init__(self, word_emb, n_class = 9, dropout = 0.2, num_layers = 1, hidden_dim = 200, emb_dim = 300):\n",
    "        super().__init__()\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_emb)\n",
    "        self.dropout1 = nn.Dropout(p = dropout)\n",
    "        self.dropout2 = nn.Dropout(p = dropout)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim // 2,\n",
    "                            num_layers = num_layers, bidirectional=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, n_class)\n",
    "        \n",
    "    def forward(self, tokens, masks):\n",
    "        embeds = self.word_embedding(tokens)\n",
    "        embeds = self.dropout1(embeds) # (batch_size, sen_len, 256)\n",
    "        sen_len = torch.sum(masks, dim = 1, dtype = torch.int64).to('cpu') # (batch_size)\n",
    "        pack_seq = pack_padded_sequence(embeds, sen_len, batch_first = True, enforce_sorted = False)\n",
    "        lstm_out, _ = self.lstm(pack_seq)\n",
    "        lstm_out, _ = pad_packed_sequence(lstm_out, batch_first = True) # (batch_size, seq_len, hidden_size)\n",
    "        lstm_feats = self.hidden2tag(lstm_out) # （batch_size, seq_len, tagset_size)\n",
    "        lstm_feats = self.dropout2(lstm_feats)\n",
    "\n",
    "        return lstm_feats\n",
    "    \n",
    "    def predict(self, tokens, masks):\n",
    "        lstm_feats = self.forward(tokens, masks)\n",
    "        predict = torch.argmax(lstm_feats, dim = 2) # (n_batch, n_tokens)\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "args = {\n",
    "    'path': '/data/pretrained/bert-base-chinese/',\n",
    "    'bert_out_dim': 768,\n",
    "    'n_class': 9, \n",
    "    'dropout': 0.2\n",
    "}\n",
    "tokenizer = AutoTokenizer.from_pretrained('/data/pretrained/bert-base-chinese/')\n",
    "def collate(batch):\n",
    "    tokens = tokenizer([item['text'] for item in batch], \n",
    "                       padding = 'max_length', truncation = True, max_length = 40, return_tensors = 'pt')\n",
    "    labels = torch.tensor([item['labels'] for item in batch], dtype = torch.long, device = device)\n",
    "    # entity_embeds = torch.tensor([item['entity_embeds'] for item in batch], dtype = torch.float, device = device)\n",
    "    # return tokens['input_ids'].to(device), tokens['attention_mask'].to(device), labels, [item['text'] for item in batch]\n",
    "    return {\n",
    "        'tokens': tokens['input_ids'].to(device),\n",
    "        'masks': tokens['attention_mask'].to(device),\n",
    "        'labels': labels,\n",
    "        'texts': [item['text'] for item in batch],\n",
    "        # 'entity_embeds': entity_embeds,\n",
    "    }\n",
    "\n",
    "n_train, n_dev = int(0.6 * len(tagged_dataset)), int(0.2 * len(tagged_dataset))\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(tagged_dataset[:n_train], batch_size = batch_size, collate_fn = collate)\n",
    "valid_loader = DataLoader(tagged_dataset[n_train: n_train + n_dev], batch_size = batch_size, collate_fn = collate)\n",
    "test_loader = DataLoader(tagged_dataset[n_train + n_dev:], batch_size = batch_size, collate_fn = collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLinear(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('/data/pretrained/bert-base-chinese/')\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.cls = nn.Linear(args['bert_out_dim'], args['n_class'])\n",
    "        \n",
    "    def forward(self, tokens, masks, labels = None, texts = None):\n",
    "        bert_out = self.bert(tokens, masks)['last_hidden_state'] # (n_batch, n_tokens, n_emb)\n",
    "        bert_out = self.dropout(bert_out)\n",
    "        cls_out = self.cls(bert_out)\n",
    "        return cls_out\n",
    "\n",
    "    def predict(self, **batch):\n",
    "        cls_out = self.forward(batch['tokens'], batch['masks'])\n",
    "        pred = torch.max(cls_out, dim = 2).indices\n",
    "        return pred\n",
    "\n",
    "# model = BertLinear(args, tokenizer, tag_dict).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /data/pretrained/bert-base-chinese/ were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train BertLinear model with lr = 1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20240406 22:23:44] [Test] Precision: 0.214992 Recall: 0.107028 F1: 0.142911\n",
      "[20240406 22:23:44] [epoch 1] TLoss: 0.941 VLoss: 0.587 TAcc: 0.527 VAcc: 0.645\n",
      "[20240406 22:23:44] Precision: 0.215 Recall: 0.107 F1: 0.143\n",
      "[20240406 22:24:57] [Test] Precision: 0.399838 Recall: 0.467702 F1: 0.431116\n",
      "[20240406 22:24:57] [epoch 2] TLoss: 0.551 VLoss: 0.507 TAcc: 0.658 VAcc: 0.684\n",
      "[20240406 22:24:57] Precision: 0.400 Recall: 0.468 F1: 0.431\n",
      "[20240406 22:26:12] [Test] Precision: 0.454973 Recall: 0.550294 F1: 0.498114\n",
      "[20240406 22:26:12] [epoch 3] TLoss: 0.473 VLoss: 0.488 TAcc: 0.698 VAcc: 0.696\n",
      "[20240406 22:26:12] Precision: 0.455 Recall: 0.550 F1: 0.498\n",
      "[20240406 22:27:28] [Test] Precision: 0.492835 Recall: 0.599356 F1: 0.540901\n",
      "[20240406 22:27:28] [epoch 4] TLoss: 0.438 VLoss: 0.478 TAcc: 0.718 VAcc: 0.703\n",
      "[20240406 22:27:28] Precision: 0.493 Recall: 0.599 F1: 0.541\n",
      "[20240406 22:28:43] [Test] Precision: 0.508405 Recall: 0.612995 F1: 0.555823\n",
      "[20240406 22:28:43] [epoch 5] TLoss: 0.416 VLoss: 0.471 TAcc: 0.731 VAcc: 0.707\n",
      "[20240406 22:28:43] Precision: 0.508 Recall: 0.613 F1: 0.556\n",
      "[20240406 22:29:57] [Test] Precision: 0.517096 Recall: 0.627392 F1: 0.566929\n",
      "[20240406 22:29:57] [epoch 6] TLoss: 0.401 VLoss: 0.476 TAcc: 0.740 VAcc: 0.706\n",
      "[20240406 22:29:57] Precision: 0.517 Recall: 0.627 F1: 0.567\n",
      "[20240406 22:31:11] [Test] Precision: 0.519300 Recall: 0.624361 F1: 0.567005\n",
      "[20240406 22:31:11] [epoch 7] TLoss: 0.391 VLoss: 0.477 TAcc: 0.747 VAcc: 0.706\n",
      "[20240406 22:31:11] Precision: 0.519 Recall: 0.624 F1: 0.567\n",
      "[20240406 22:32:24] [Test] Precision: 0.519602 Recall: 0.622656 F1: 0.566480\n",
      "[20240406 22:32:24] [epoch 8] TLoss: 0.381 VLoss: 0.478 TAcc: 0.752 VAcc: 0.705\n",
      "[20240406 22:32:24] Precision: 0.520 Recall: 0.623 F1: 0.566\n",
      "[20240406 22:33:37] [Test] Precision: 0.525064 Recall: 0.623035 F1: 0.569869\n",
      "[20240406 22:33:37] [epoch 9] TLoss: 0.374 VLoss: 0.478 TAcc: 0.756 VAcc: 0.705\n",
      "[20240406 22:33:37] Precision: 0.525 Recall: 0.623 F1: 0.570\n",
      "[20240406 22:34:50] [Test] Precision: 0.523447 Recall: 0.625876 F1: 0.570097\n",
      "[20240406 22:34:50] [epoch 10] TLoss: 0.366 VLoss: 0.476 TAcc: 0.762 VAcc: 0.705\n",
      "[20240406 22:34:50] Precision: 0.523 Recall: 0.626 F1: 0.570\n",
      "[20240406 22:34:50] Early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model to ./results/BertLinear.1e-06.04062234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20240406 22:34:58] [Test] Precision: 0.540802 Recall: 0.523449 F1: 0.531984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5408024481467968, 0.5234490702648472, 0.5319842791220859)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BertLinear\n",
    "model = BertLinear(args).to(device)\n",
    "train(model, train_loader, valid_loader, epochs = 100, lr = 1e-6)\n",
    "evaluate(model, test_loader, tag_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT ABSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接使用MLP对于进行分类\n",
    "class BertLinear2(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('/data/pretrained/bert-base-chinese/')\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.cls = nn.Linear(args['bert_out_dim'], args['n_class'])\n",
    "        \n",
    "    def forward(self, **batch):\n",
    "        bert_out = self.bert(batch['tokens'], batch['masks'])['last_hidden_state'] # (n_batch, n_tokens, n_emb)\n",
    "        bert_out = self.dropout(bert_out)\n",
    "        cls_out = self.cls(bert_out)\n",
    "        return cls_out\n",
    "\n",
    "    def predict_tagging(self, **batch):\n",
    "        cls_out = self.forward(batch['tokens'], batch['masks'])\n",
    "        pred = torch.max(cls_out, dim = 2).indices\n",
    "        return pred\n",
    "\n",
    "    # NER\n",
    "    def predict(self, **batch):\n",
    "        # sequence tagging\n",
    "        cls_out = self.forward(**batch)\n",
    "        pred = torch.max(cls_out, dim = 2).indices\n",
    "        return pred\n",
    "    \n",
    "    # decode from BIOES\n",
    "    def decode(self, pred, labels, texts):\n",
    "        # NER: decode from BIOES\n",
    "        pred_entities, gold_entities = decode_ner(pred, labels, texts)\n",
    "        # pred_entities, gold_entities = decode_ner(pred, batch['labels'], batch['texts'])\n",
    "        # metrics\n",
    "        # precision, recall, f1 = ner_metrics(pred_entities, gold_entities)\n",
    "        return pred_entities, gold_entities\n",
    "        pass\n",
    "    \n",
    "    \n",
    "# model = BertLinear(args, tokenizer, tag_dict).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /data/pretrained/bert-base-chinese/ were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train BertLinearNER model with lr = 1e-06\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m BertLinearNER(args)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m evaluate(model, test_loader, tag_list)\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, valid_loader, loss_mode, epochs, lr)\u001b[0m\n\u001b[1;32m     25\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m     predict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch) \u001b[38;5;66;03m# (n_batch, n_tokens)\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     train_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mlogical_and(predict \u001b[38;5;241m==\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m][:, :\u001b[43mpredict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m1\u001b[39m]], batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     28\u001b[0m     train_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     29\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(train_losses)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model = BertLinearNER(args).to(device)\n",
    "train(model, train_loader, valid_loader, epochs = 100, lr = 1e-6)\n",
    "evaluate(model, test_loader, tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
